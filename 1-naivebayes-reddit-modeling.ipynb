{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification Modeling - r/biology & r/biochemistry Predicting with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, plot_confusion_matrix\n",
    "\n",
    "#lemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Import stemmer.\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# Import RegEx Tokenizer\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of userwarning when running code and getting tokenized words not in the stop words list\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the submissions csv file\n",
    "#get rid of unnamed:0 column wtih index_col\n",
    "submissions = pd.read_csv('datasets/cleaned-submission.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11007 entries, 0 to 6228\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  11007 non-null  object\n",
      " 1   selftext   10941 non-null  object\n",
      " 2   title      11002 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 344.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#getting the information from submissions\n",
    "#there are null values present\n",
    "submissions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6227</th>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>so far ive mostly looked for stuff in my homet...</td>\n",
       "      <td>wanting to take a year off between undergrad a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6228</th>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>im currently taking a biochemistry class at un...</td>\n",
       "      <td>biochemistry help</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                           selftext  \\\n",
       "6227  Biochemistry  so far ive mostly looked for stuff in my homet...   \n",
       "6228  Biochemistry  im currently taking a biochemistry class at un...   \n",
       "\n",
       "                                                  title  \n",
       "6227  wanting to take a year off between undergrad a...  \n",
       "6228                                  biochemistry help  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#observing the presence of subreddit names within the text below\n",
    "submissions.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop any null values\n",
    "submissions.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all words that apply to the target variable -- biology,bio,biochem,biochemistry\n",
    "submissions['selftext'].replace('biology','',regex=True,inplace=True)\n",
    "submissions['selftext'].replace('biochemistry','',regex=True,inplace=True)\n",
    "submissions['selftext'].replace('chemistry','',regex=True,inplace=True)\n",
    "submissions['selftext'].replace('biochem','',regex=True,inplace=True)\n",
    "submissions['selftext'].replace('bio','',regex=True,inplace=True)\n",
    "submissions['selftext'].replace('chem','',regex=True,inplace=True)\n",
    "\n",
    "submissions['title'].replace('biology','',regex=True,inplace=True)\n",
    "submissions['title'].replace('biochemistry','',regex=True,inplace=True)\n",
    "submissions['title'].replace('chemistry','',regex=True,inplace=True)\n",
    "submissions['title'].replace('biochem','',regex=True,inplace=True)\n",
    "submissions['title'].replace('bio','',regex=True,inplace=True)\n",
    "submissions['title'].replace('chem','',regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6227</th>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>so far ive mostly looked for stuff in my homet...</td>\n",
       "      <td>wanting to take a year off between undergrad a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6228</th>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>im currently taking a  class at university im ...</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                           selftext  \\\n",
       "6227  Biochemistry  so far ive mostly looked for stuff in my homet...   \n",
       "6228  Biochemistry  im currently taking a  class at university im ...   \n",
       "\n",
       "                                                  title  \n",
       "6227  wanting to take a year off between undergrad a...  \n",
       "6228                                               help  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#observing the loss of subreddit names\n",
    "#it is now removed from the text\n",
    "submissions.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10936, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the shape of the submissions dataframe\n",
    "submissions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing The Above Words Explained:\n",
    "\n",
    "Part of the data science question I am interested in is whether the subreddits, r/biology and r/biochemsitry, can be classified using scientific terminology; for example carbohydrate metabolism or gymnosperm. Carbohydrate metabolism is one of the main biochemical processes that produces energy for cells. A gymnosperm is a group of seed-producing plants and a biological term. Therfore, I did not want versions of the words 'biology', which was present in over 2,000 of the r/biology selftext posts, or 'biochemsitry', which was present in over 1,500 biochemistry selftext posts, to have a significant influence on classification of the posts. In this project, I wished to solely focus the NLP model classification to prominent scientific terms or other meaningful words to classify the subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with Title Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up initial X and y values -- using titles only first\n",
    "#1 corresponds to biochemistry, 0 corresponds to biology\n",
    "#need to make the str unicode with astype, emoji characters in the strings\n",
    "#help with the unicode error found below:\n",
    "#https://stackoverflow.com/questions/39303912/tfidfvectorizer-in-scikit-learn-valueerror-np-nan-is-an-invalid-document\n",
    "X = submissions['title'].values.astype('U')\n",
    "y = np.where(submissions['subreddit']=='Biochemistry',1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Most Common Title Text without Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count vectorize words to find the most common\n",
    "cvect = CountVectorizer()\n",
    "Xvect = cvect.fit_transform(X)\n",
    "#make it a dataframe\n",
    "dtm = pd.DataFrame(Xvect.toarray(),columns = cvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make a graph of the most common words\n",
    "dtm.sum().sort_values(ascending=False).head(10).plot(kind='bar',figsize=(10,6),\n",
    "                                                    color='#9370DB')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Word Counts')\n",
    "plt.title('The 10 Most Common Words in Reddit Titles');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Interpretation:\n",
    "\n",
    "The graph above shows the 10 most common words in the titles of the subreddits posts from r/biology and r/biochemistry. As you can see, a majority of the most common words are prepositions - words such as the, to, in, etc. These prepositional words do not have any significant meaning to predicting whether a post will more likely be in r/biology or r/biochemistry so they will be removed from the models with the stop_words parameter in either CountVetorizer or TfidfVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step over collection of tokens and try to lemmatize each of them\n",
    "#to use in countvectorizer we pass the new class as the tokenizer\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    def __call__(self,doc):\n",
    "        return [self.lemmatizer.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step over collection of word tokens and stemmatize\n",
    "#create a class to pass into Countvectorizer in a pipeline\n",
    "class StemTokenizer:\n",
    "    def __init__(self):\n",
    "        self.stemmatizer = PorterStemmer()\n",
    "    def __call__(self,doc):\n",
    "        return [self.stemmatizer.stem(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LemmaTokenizer and StemTokenizer Explained:\n",
    "\n",
    "The two above classes, LemmaTokenize and StemTokenizer were created so that lemmatization or stemmatization of the text could be done within a CountVectorizer or TfidfVectorizer object. These classes are especially useful for doing lemmatizing or stemming within pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#longer list of stop words\n",
    "#taken from the open source work found here: https://gist.github.com/sebleier/554280\n",
    "#txt found here: https://gist.githubusercontent.com/ZohebAbai/513218c3468130eacff6481f424e4e64/raw/b70776f341a148293ff277afa0d0302c8c38f7e2/gist_stopwords.txt\n",
    "\n",
    "stop_word = pd.read_csv('datasets/stopwords.csv',index_col=0)\n",
    "stop_word = list(stop_word['stopwords'])\n",
    "\n",
    "#remove punctuation from the stop words, as it has already been done in cleaning the text\n",
    "stop_word = [word.replace(\"'\",'') for word in stop_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated stop_words to csv file for use in other modeling notebookes\n",
    "#code cell can be used to append other stop_words to the csv file\n",
    "#to make this occur uncomment the below code\n",
    "\n",
    "# df_stopwords = pd.DataFrame({'stopwords':stop_word})\n",
    "# df_stopwords.to_csv('./datasets/stopwords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stopwords.csv Explained:\n",
    "\n",
    "I discovered through some investigation that the above stop words list allowed modeling to perform better, than usage of stop_words = 'english' in CountVectorizer and TfidfVectorizer. The removal of more extraneous words - which have no significance to r/biology or r/biochemistry - allowed for better accuracy in modeling that occurred below. Thus, I used a currated file of stop words in each other modeling notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling With Only Title Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratify to get more equal target variables in the train/test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,random_state=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model With Text Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent class is r/biochemistry. The accuracy of the null model is 0.5686.\n"
     ]
    }
   ],
   "source": [
    "#to get the baseline accuracy of the model\n",
    "#based on the most frequent value in the training data\n",
    "#biochemistry = 1, biology = 0\n",
    "\n",
    "biochem_num = y_train.sum()\n",
    "biology_num = len(y_train)-biochem_num\n",
    "\n",
    "if biology_num < biochem_num:\n",
    "    baseline_accur = round(biochem_num/len(y_train),4)\n",
    "    print(f'The most frequent class is r/biochemistry. The accuracy of the null model is {baseline_accur}.')\n",
    "    \n",
    "else:\n",
    "    baseline_accuracy = round((biology_num)/len(y_train),4)\n",
    "    print(f'The most frequent class is r/biology. The accuracy of the null model is {baseline_accuracy}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline/Null Model Explained:\n",
    "\n",
    "The baseline model allows us to find a 'starting point' to compare the performance of future models to. In binary classification, a customary baseline/null model is one that will guess the most frequently occuring class in the training set. The code above is a way to print out what the baseline accuracy of the null model actually is. With the random state of the train/test split set, this accuracy should not change with future restarts of the kernel. The most frequent class is that of r/biochemistry. Therefore, there is a 56.8% accuracy if you were to guess r/biochemsitry for every observation within the data set. \n",
    "\n",
    "Let's see if we can't improve on this score with some NLP modeling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Metrics for this NLP Data Science Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metric I want to focus on for this data science problem is both accuracy and recall. I want to try and optimize recall, along with accuracy - I think that this is important for several reasons. \n",
    "\n",
    "\n",
    "For accuracy, I want the NLP model to be able to predict the correct subreddit for a post as well as possible. In the cruel land of forums - depending on the subreddit or specific forum page - a user can become banned from that forum just for posting something that is not aligned with that page's identity. Also, if you are asking a specific biology/biochemistry question, you want your post to go to the right forum, so you can get the best answer/explanation possible.\n",
    "\n",
    "For recall, I think, in this case, it is important to optimize the true positive rate. As we are trying to model towards a success of r/biochemistry, it is important to minimize the number of false negatives (incorrectly classified true r/biochemistry posts). r/biochemistry is a more specialized branch of biology and so it is important that you try to capture these biochemical/molecular-based posts into r/biochemistry, where they truly belong. Get as many r/biochemistry posts into the correct classification of r/biochemistry so you are getting the help you need from the members of that subreddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model One. Default Naive Bayes, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a pipeline for Naive Bayes Classifer\n",
    "#search pipeline through gridsearch\n",
    "cvect_NB = CountVectorizer(stop_words = stop_word)\n",
    "pipe_NB = make_pipeline(cvect_NB, StandardScaler(with_mean=False), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(stop_words=['0o', '0s', '3a', '3b', '3d', '6b',\n",
       "                                             '6o', 'a', 'a1', 'a2', 'a3', 'a4',\n",
       "                                             'ab', 'able', 'about', 'above',\n",
       "                                             'abst', 'ac', 'accordance',\n",
       "                                             'according', 'accordingly',\n",
       "                                             'across', 'act', 'actually', 'ad',\n",
       "                                             'added', 'adj', 'ae', 'af',\n",
       "                                             'affected', ...])),\n",
       "                ('standardscaler', StandardScaler(with_mean=False)),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initial model with minimal hyperparam tuning\n",
    "#lemmatizer produce the following things not in stop words = 'ha','le','u','wa'\n",
    "pipe_NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894762484774665"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the score on the training set is high, suspiciously high\n",
    "pipe_NB.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6784800876872488"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the score on the training set shows there is a lot of overfitting occuring \n",
    "#remove high variance with hyperparameter tuning\n",
    "pipe_NB.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7633440514469454"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall score on the first default naive bayes with title\n",
    "recall_score(y_test,pipe_NB.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation:\n",
    "\n",
    "This model is a sort of baseline model, to see if the hypertuning of parameters for both CountVectorization and the estimator, MultinomialNB, can improve the score. This 'default' model is already performing better than the baseline model. It is scoring approximately 10% better on accuracy than the null model and has a recall score of 76.3%. Let's see how hypertuning the parameters for this model changes the classification metrics we are interested in. We can also see that this default model is overfit to the training data, as there is a big difference between the accuracy scores for the training data and the holdout testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Two. GridSearchCV Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params for bayes classifier\n",
    "#Bayes with CountVectorizer\n",
    "param_grid_NB = {\n",
    "    'countvectorizer__max_features':[3_250,3_500,3_250],\n",
    "    'multinomialnb__alpha':[3_975,3_965,3_980],\n",
    "    'countvectorizer__ngram_range':[(1,1),(1,2),(2,2)]\n",
    "}\n",
    "grid_NB = GridSearchCV(pipe_NB,param_grid = param_grid_NB,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                        CountVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...])),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('multinomialnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'countvectorizer__max_features': [3250, 3500, 3250],\n",
       "                         'countvectorizer__ngram_range': [(1, 1), (1, 2),\n",
       "                                                          (2, 2)],\n",
       "                         'multinomialnb__alpha': [3975, 3965, 3980]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit on the training data\n",
    "grid_NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__max_features': 3250,\n",
       " 'countvectorizer__ngram_range': (1, 1),\n",
       " 'multinomialnb__alpha': 3975}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the best parameters\n",
    "grid_NB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7075517661388551"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best accuracy score for the model\n",
    "grid_NB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8029232643118148"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score on the training data\n",
    "grid_NB.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_countvectorizer__ngram_range</th>\n",
       "      <th>param_multinomialnb__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>0.024022</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>3250</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>3975</td>\n",
       "      <td>{'countvectorizer__max_features': 3250, 'count...</td>\n",
       "      <td>0.705238</td>\n",
       "      <td>0.694884</td>\n",
       "      <td>0.70341</td>\n",
       "      <td>0.711937</td>\n",
       "      <td>0.72229</td>\n",
       "      <td>0.707552</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.106897</td>\n",
       "      <td>0.006374</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>3250</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>3965</td>\n",
       "      <td>{'countvectorizer__max_features': 3250, 'count...</td>\n",
       "      <td>0.705238</td>\n",
       "      <td>0.694884</td>\n",
       "      <td>0.70341</td>\n",
       "      <td>0.711937</td>\n",
       "      <td>0.72229</td>\n",
       "      <td>0.707552</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.104896</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.020418</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>3250</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>3980</td>\n",
       "      <td>{'countvectorizer__max_features': 3250, 'count...</td>\n",
       "      <td>0.705238</td>\n",
       "      <td>0.694884</td>\n",
       "      <td>0.70341</td>\n",
       "      <td>0.711937</td>\n",
       "      <td>0.72229</td>\n",
       "      <td>0.707552</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.110300      0.006311         0.024022        0.005064   \n",
       "1       0.106897      0.006374         0.020619        0.001021   \n",
       "2       0.104896      0.003253         0.020418        0.000801   \n",
       "\n",
       "  param_countvectorizer__max_features param_countvectorizer__ngram_range  \\\n",
       "0                                3250                             (1, 1)   \n",
       "1                                3250                             (1, 1)   \n",
       "2                                3250                             (1, 1)   \n",
       "\n",
       "  param_multinomialnb__alpha  \\\n",
       "0                       3975   \n",
       "1                       3965   \n",
       "2                       3980   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'countvectorizer__max_features': 3250, 'count...           0.705238   \n",
       "1  {'countvectorizer__max_features': 3250, 'count...           0.705238   \n",
       "2  {'countvectorizer__max_features': 3250, 'count...           0.705238   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.694884            0.70341           0.711937            0.72229   \n",
       "1           0.694884            0.70341           0.711937            0.72229   \n",
       "2           0.694884            0.70341           0.711937            0.72229   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.707552        0.009159                1  \n",
       "1         0.707552        0.009159                1  \n",
       "2         0.707552        0.009159                1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get a dataframe of the results\n",
    "pd.DataFrame(grid_NB.cv_results_).sort_values(by='rank_test_score').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive Bayes model is 0.696.\n",
      "The recall of the Naive Bayes model is 0.8444.\n",
      "The f1 score of the Naive Bayes model is 0.7594.\n",
      "The precision score of the Naive Bayes model is 0.69.\n"
     ]
    }
   ],
   "source": [
    "#score on different classification metrics\n",
    "print(f'The accuracy of the Naive Bayes model is {round(grid_NB.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Naive Bayes model is {round(recall_score(y_test,grid_NB.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Naive Bayes model is {round(f1_score(y_test,grid_NB.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Naive Bayes model is {round(precision_score(y_test,grid_NB.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation:\n",
    "\n",
    "Model Two is Model One with hypertuning of the major parameters in the CountVectorizer transformer and MultinomialNB estimator. Compared to the 'default' Model One, this hypertuned model scores slightly better: ~2% better accuracy and ~10% better recall score. Model Two is way less overfit than Model One, creating a model with more accurate coefficient values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Three. GridSearchCV Naive Bayes, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate tfidf vectorizer and pipeline\n",
    "tfidf_nb = TfidfVectorizer()\n",
    "pipenb_tfidf = make_pipeline(tfidf_nb, StandardScaler(with_mean=False),MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create parameters for the tfidf model\n",
    "params = {\n",
    "    'tfidfvectorizer__max_features':[5_000,6_500],\n",
    "    'multinomialnb__alpha':[4_600,4_750,4_800],\n",
    "    'tfidfvectorizer__ngram_range':[(1,1),(1,2),(2,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate gridsearch object for tfidf\n",
    "grid_tf = GridSearchCV(pipenb_tfidf,param_grid = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('multinomialnb', MultinomialNB())]),\n",
       "             param_grid={'multinomialnb__alpha': [4600, 4750, 4800],\n",
       "                         'tfidfvectorizer__max_features': [5000, 6500],\n",
       "                         'tfidfvectorizer__ngram_range': [(1, 1), (1, 2),\n",
       "                                                          (2, 2)]})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit training data to the tfidf gridsearch object\n",
    "grid_tf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.770939548434086"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy on training set\n",
    "#overfit model -- 7% higher training accuracy, than test accuracy\n",
    "grid_tf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive Bayes model with TfidfVectorization is 0.7015.\n",
      "The recall of the Naive Bayes model with TfidfVectorization is 0.8418.\n",
      "The f1 score of the Naive Bayes model with TfidfVectorization is 0.7622.\n",
      "The precision score of the Naive Bayes with TfidfVectorization model is 0.6963.\n"
     ]
    }
   ],
   "source": [
    "#score on different classification metrics on title data\n",
    "print(f'The accuracy of the Naive Bayes model with TfidfVectorization is {round(grid_tf.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Naive Bayes model with TfidfVectorization is {round(recall_score(y_test,grid_tf.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Naive Bayes model with TfidfVectorization is {round(f1_score(y_test,grid_tf.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Naive Bayes with TfidfVectorization model is {round(precision_score(y_test,grid_tf.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multinomialnb__alpha': 4600,\n",
       " 'tfidfvectorizer__max_features': 5000,\n",
       " 'tfidfvectorizer__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the best parameters for the gridsearch\n",
    "grid_tf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(max_features=5000)),\n",
       "                ('standardscaler', StandardScaler(with_mean=False)),\n",
       "                ('multinomialnb', MultinomialNB(alpha=4600))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best estimator of the grid\n",
    "grid_tf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_multinomialnb__alpha</th>\n",
       "      <th>param_tfidfvectorizer__max_features</th>\n",
       "      <th>param_tfidfvectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067862</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.014613</td>\n",
       "      <td>0.00049</td>\n",
       "      <td>4600</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'multinomialnb__alpha': 4600, 'tfidfvectorize...</td>\n",
       "      <td>0.694275</td>\n",
       "      <td>0.701583</td>\n",
       "      <td>0.709501</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.718027</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>0.008158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.066661</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.013812</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>4750</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'multinomialnb__alpha': 4750, 'tfidfvectorize...</td>\n",
       "      <td>0.693666</td>\n",
       "      <td>0.700365</td>\n",
       "      <td>0.710110</td>\n",
       "      <td>0.700974</td>\n",
       "      <td>0.716809</td>\n",
       "      <td>0.704385</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.067862      0.001328         0.014613         0.00049   \n",
       "6       0.066661      0.000490         0.013812         0.00040   \n",
       "\n",
       "  param_multinomialnb__alpha param_tfidfvectorizer__max_features  \\\n",
       "0                       4600                                5000   \n",
       "6                       4750                                5000   \n",
       "\n",
       "  param_tfidfvectorizer__ngram_range  \\\n",
       "0                             (1, 1)   \n",
       "6                             (1, 1)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'multinomialnb__alpha': 4600, 'tfidfvectorize...           0.694275   \n",
       "6  {'multinomialnb__alpha': 4750, 'tfidfvectorize...           0.693666   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.701583           0.709501           0.700974           0.718027   \n",
       "6           0.700365           0.710110           0.700974           0.716809   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.704872        0.008158                1  \n",
       "6         0.704385        0.008122                2  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the top 2 results of the gridsearch parameters\n",
    "pd.DataFrame(grid_tf.cv_results_).sort_values(by='rank_test_score').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation:\n",
    "\n",
    "Model Three is a Multinomial Naive Bayes performed with TfidfVectorization, rather than CountVectorization. TfidfVectorization measures the importance of a word based on how many times a word appears in a document versus the number of documents that word appears in. The TfidfVectorization slightly increases accuracy, but drops recall slightly. Overall there is not a significant difference between TfidfVectorization or CountVectorization - in terms of the evaluation metrics we are focusing on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>protein</th>\n",
       "      <td>-7.837321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <td>-7.848632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advice</th>\n",
       "      <td>-7.918840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enzyme</th>\n",
       "      <td>-7.928840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acid</th>\n",
       "      <td>-7.931591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amino</th>\n",
       "      <td>-7.941631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>-7.947803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lab</th>\n",
       "      <td>-7.948100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proteins</th>\n",
       "      <td>-7.949230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phd</th>\n",
       "      <td>-7.954429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coefs\n",
       "protein  -7.837321\n",
       "question -7.848632\n",
       "advice   -7.918840\n",
       "enzyme   -7.928840\n",
       "acid     -7.931591\n",
       "amino    -7.941631\n",
       "major    -7.947803\n",
       "lab      -7.948100\n",
       "proteins -7.949230\n",
       "phd      -7.954429"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the most important words for modeling with title\n",
    "coefs = grid_NB.best_estimator_.named_steps['multinomialnb'].coef_\n",
    "words = grid_NB.best_estimator_.named_steps['countvectorizer'].get_feature_names()\n",
    "coefs_df = pd.DataFrame({'coefs':coefs[0]}, \n",
    "                       index = words)\n",
    "coefs_df.nlargest(10,'coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01mm</th>\n",
       "      <td>-8.116511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-8.116511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-8.116511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>-8.116511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>-8.116511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>-8.116511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>-8.116511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>-8.116511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-8.116511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25c</th>\n",
       "      <td>-8.116511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coefs\n",
       "01mm  -8.116511\n",
       "151   -8.116511\n",
       "170   -8.116511\n",
       "18449 -8.116511\n",
       "2009  -8.116511\n",
       "2019  -8.116511\n",
       "2021  -8.116511\n",
       "227   -8.116511\n",
       "23    -8.116511\n",
       "25c   -8.116511"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the least important words for classification\n",
    "coefs_df.nsmallest(10,'coefs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling With Selftext Only\n",
    "\n",
    "In this first notebook, I wanted to compare how using title text only, selftext only, and a combination of title and selftext would impact model scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10947"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of rows of selftext\n",
    "len(submissions['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up initial X and y values -- using titles only first\n",
    "#1 corresponds to biochemistry, 0 corresponds to biology\n",
    "#need to make the str unicode with astype, emoji characters in the strings\n",
    "#help with the unicode error found below:\n",
    "#https://stackoverflow.com/questions/39303912/tfidfvectorizer-in-scikit-learn-valueerror-np-nan-is-an-invalid-document\n",
    "X_selftext = submissions['selftext']\n",
    "y = np.where(submissions['subreddit']=='Biochemistry',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count vectorize words to find the most common\n",
    "cvect_selftext = CountVectorizer()\n",
    "Xvect_selftext = cvect_selftext.fit_transform(X_selftext)\n",
    "#make it a dataframe\n",
    "dtm_selftext = pd.DataFrame(Xvect_selftext.toarray(),columns = cvect_selftext.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make a graph of the most common words\n",
    "dtm_selftext.sum().sort_values(ascending=False).head(10).plot(kind='bar',\n",
    "                                                              figsize=(12,7),\n",
    "                                                             color='#9370DB')\n",
    "plt.xlabel('Word'),\n",
    "plt.ylabel('Word Count')\n",
    "plt.title('The 10 Most Common Words in Reddit Posts');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Interpretation:\n",
    "\n",
    "The graph above shows the 10 most common words in the selftext/body of the subreddits posts from r/biology and r/biochemistry. As you can see, a majority of the most common words are prepositions - words such as the, to, in, etc. These prepositional words do not have any significant meaning to predicting whether a post will more likely be in r/biology or r/biochemistry so they will be removed from the models with the stop_words parameter in either CountVetorizer or TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the     36000\n",
       "to      28784\n",
       "and     23849\n",
       "of      20028\n",
       "in      18209\n",
       "is      14331\n",
       "that    12113\n",
       "for     10490\n",
       "it      10338\n",
       "my       9003\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another view of the top 10 most common words from the selftext\n",
    "dtm_selftext.sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratify to get more equal target variables in the train/test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_selftext,y,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model Score for Selftext Only Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent class is r/biochemistry. The accuracy of the null model is 0.5686.\n"
     ]
    }
   ],
   "source": [
    "#to get the baseline accuracy of the model\n",
    "#based on the most frequent value in the training data\n",
    "#biochemistry = 1, biology = 0\n",
    "\n",
    "biochem_num = y_train.sum()\n",
    "biology_num = len(y_train)-biochem_num\n",
    "\n",
    "if biology_num < biochem_num:\n",
    "    baseline_accur = round(biochem_num/len(y_train),4)\n",
    "    print(f'The most frequent class is r/biochemistry. The accuracy of the null model is {baseline_accur}.')\n",
    "    \n",
    "else:\n",
    "    baseline_accuracy = round((biology_num)/len(y_train),4)\n",
    "    print(f'The most frequent class is r/biology. The accuracy of the null model is {baseline_accuracy}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline/Null Model Explained:\n",
    "\n",
    "The baseline model allows us to find a 'starting point' to compare the performance of future models to. In binary classification, a customary baseline/null model is one that will guess the most frequently occuring class in the testing set. Baseline accuracy is 56.81%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model One. Naive Bayes - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(stop_words=['0o', '0s', '3a', '3b', '3d', '6b',\n",
       "                                             '6o', 'a', 'a1', 'a2', 'a3', 'a4',\n",
       "                                             'ab', 'able', 'about', 'above',\n",
       "                                             'abst', 'ac', 'accordance',\n",
       "                                             'according', 'accordingly',\n",
       "                                             'across', 'act', 'actually', 'ad',\n",
       "                                             'added', 'adj', 'ae', 'af',\n",
       "                                             'affected', ...])),\n",
       "                ('standardscaler', StandardScaler(with_mean=False)),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create pipeline for Naive Bayes modeling with selftext\n",
    "cvect_selftext = CountVectorizer(stop_words=stop_word)\n",
    "pipeNB_selftext = make_pipeline(cvect_selftext, StandardScaler(with_mean=False), MultinomialNB())\n",
    "pipeNB_selftext.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9476248477466505"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score\n",
    "pipeNB_selftext.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6814029959810011"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the highest accuracy\n",
    "pipeNB_selftext.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7427652733118971"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the recall score\n",
    "recall_score(y_test,pipeNB_selftext.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation:\n",
    "\n",
    "This is another 'default' model I used to gauge if hyperparameter tuning would increase the evaluation metrics of choice when using selftext to model. I also used this 'default' selftext model to compare the scores achieved with an exact model that used title text only as the predictive features. Comparing the two default models, there is not a large difference in accuracy and recall. The 'default' model is also highly overfit, and should be tuned to reduce this high variance, in hopes of improving the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Two. GridSearchCV Naive Bayes, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the parameter grid for the gridsearchCV\n",
    "param_selftext = {\n",
    "    'countvectorizer__max_features': [1250,2500,3500],\n",
    "    'countvectorizer__ngram_range':[(1,1),(1,2),(2,2)],\n",
    "    'multinomialnb__alpha':[300,500,750]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                        CountVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...])),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('multinomialnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'countvectorizer__max_features': [1250, 2500, 3500],\n",
       "                         'countvectorizer__ngram_range': [(1, 1), (1, 2),\n",
       "                                                          (2, 2)],\n",
       "                         'multinomialnb__alpha': [300, 500, 750]})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate pipeline instance in GridSearchCV\n",
    "grid_selftext = GridSearchCV(pipeNB_selftext, param_grid = param_selftext,n_jobs=-1)\n",
    "\n",
    "#fit training data to gridsearch CV\n",
    "grid_selftext.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7867235079171742"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best score\n",
    "grid_selftext.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive Bayes model with CountVectorization is 0.741.\n",
      "The recall of the Naive Bayes model with CountVectorization is 0.8521.\n",
      "The f1 score of the Naive Bayes model with CountVectorization is 0.7889.\n",
      "The precision score of the Naive Bayes model with CountVectorization is 0.7345.\n"
     ]
    }
   ],
   "source": [
    "#score on different classification metrics\n",
    "print(f'The accuracy of the Naive Bayes model with CountVectorization is {round(grid_selftext.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Naive Bayes model with CountVectorization is {round(recall_score(y_test,grid_selftext.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Naive Bayes model with CountVectorization is {round(f1_score(y_test,grid_selftext.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Naive Bayes model with CountVectorization is {round(precision_score(y_test,grid_selftext.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__max_features': 3500,\n",
       " 'countvectorizer__ngram_range': (1, 1),\n",
       " 'multinomialnb__alpha': 500}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best parameters\n",
    "grid_selftext.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_countvectorizer__ngram_range</th>\n",
       "      <th>param_multinomialnb__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.517604</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.127115</td>\n",
       "      <td>0.025885</td>\n",
       "      <td>3500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>500</td>\n",
       "      <td>{'countvectorizer__max_features': 3500, 'count...</td>\n",
       "      <td>0.750305</td>\n",
       "      <td>0.739342</td>\n",
       "      <td>0.728380</td>\n",
       "      <td>0.744823</td>\n",
       "      <td>0.739951</td>\n",
       "      <td>0.740560</td>\n",
       "      <td>0.007257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.521895</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>3500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>300</td>\n",
       "      <td>{'countvectorizer__max_features': 3500, 'count...</td>\n",
       "      <td>0.746650</td>\n",
       "      <td>0.740560</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>0.745432</td>\n",
       "      <td>0.740560</td>\n",
       "      <td>0.740073</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.623076</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>0.152138</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>3500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>300</td>\n",
       "      <td>{'countvectorizer__max_features': 3500, 'count...</td>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.739342</td>\n",
       "      <td>0.722899</td>\n",
       "      <td>0.744823</td>\n",
       "      <td>0.747868</td>\n",
       "      <td>0.739829</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.614869</td>\n",
       "      <td>0.045272</td>\n",
       "      <td>0.170755</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>3500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>500</td>\n",
       "      <td>{'countvectorizer__max_features': 3500, 'count...</td>\n",
       "      <td>0.747868</td>\n",
       "      <td>0.734470</td>\n",
       "      <td>0.722899</td>\n",
       "      <td>0.739951</td>\n",
       "      <td>0.747868</td>\n",
       "      <td>0.738611</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "19       0.517604      0.028674         0.127115        0.025885   \n",
       "18       0.521895      0.011370         0.110300        0.010694   \n",
       "21       1.623076      0.006411         0.152138        0.011961   \n",
       "22       1.614869      0.045272         0.170755        0.014035   \n",
       "\n",
       "   param_countvectorizer__max_features param_countvectorizer__ngram_range  \\\n",
       "19                                3500                             (1, 1)   \n",
       "18                                3500                             (1, 1)   \n",
       "21                                3500                             (1, 2)   \n",
       "22                                3500                             (1, 2)   \n",
       "\n",
       "   param_multinomialnb__alpha  \\\n",
       "19                        500   \n",
       "18                        300   \n",
       "21                        300   \n",
       "22                        500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "19  {'countvectorizer__max_features': 3500, 'count...           0.750305   \n",
       "18  {'countvectorizer__max_features': 3500, 'count...           0.746650   \n",
       "21  {'countvectorizer__max_features': 3500, 'count...           0.744214   \n",
       "22  {'countvectorizer__max_features': 3500, 'count...           0.747868   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "19           0.739342           0.728380           0.744823   \n",
       "18           0.740560           0.727162           0.745432   \n",
       "21           0.739342           0.722899           0.744823   \n",
       "22           0.734470           0.722899           0.739951   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "19           0.739951         0.740560        0.007257                1  \n",
       "18           0.740560         0.740073        0.006916                2  \n",
       "21           0.747868         0.739829        0.008896                3  \n",
       "22           0.747868         0.738611        0.009351                4  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_selftext.cv_results_).sort_values(by='rank_test_score').head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation:\n",
    "\n",
    "Model Two was where I began to see that the selftext only was scoring better on accuracy, than with the title text. The accuracy of Model Two scored about ~3% better than any of the models which used title text. For the remainder of models which used selftext I kept a close on the accuracy score between title and selftext, you will see that the selftext models perform better on accuracy across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Three. GridSearchCV Naive Bayes with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate tfidf vectorizer and pipeline\n",
    "tfdfNB_selftext = TfidfVectorizer(stop_words = stop_word)\n",
    "pipeNBtddf_selftext = make_pipeline(tfdfNB_selftext, StandardScaler(with_mean=False),MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter grid for TfidfVectorizer and Bayes\n",
    "param_tfdf_selftext = {\n",
    "    'tfidfvectorizer__max_features': [4_750,5_000,5_250],\n",
    "    'tfidfvectorizer__ngram_range':[(1,1),(1,2)],\n",
    "    'multinomialnb__alpha':[635,650,645,630]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...])),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('multinomialnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'multinomialnb__alpha': [635, 650, 645, 630],\n",
       "                         'tfidfvectorizer__max_features': [4750, 5000, 5250],\n",
       "                         'tfidfvectorizer__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit training data to tfidf gridsearch\n",
    "grid_tfdf_self = GridSearchCV(pipeNBtddf_selftext,param_grid=param_tfdf_selftext,n_jobs=-1)\n",
    "grid_tfdf_self.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8237515225334957"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the accuracy score on the training set\n",
    "grid_tfdf_self.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multinomialnb__alpha': 650,\n",
       " 'tfidfvectorizer__max_features': 5000,\n",
       " 'tfidfvectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the best parameters\n",
    "grid_tfdf_self.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive Bayes model with TfidfVectorization is 0.7421.\n",
      "The recall of the Naive Bayes model with TfidfVectorization is 0.8553.\n",
      "The f1 score of the Naive Bayes model with TfidfVectorization is 0.7903.\n",
      "The precision score of the Naive Bayes model with TfidfVectorization is 0.7344.\n"
     ]
    }
   ],
   "source": [
    "#score on different classification metrics\n",
    "print(f'The accuracy of the Naive Bayes model with TfidfVectorization is {round(grid_tfdf_self.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Naive Bayes model with TfidfVectorization is {round(recall_score(y_test,grid_tfdf_self.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Naive Bayes model with TfidfVectorization is {round(f1_score(y_test,grid_tfdf_self.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Naive Bayes model with TfidfVectorization is {round(precision_score(y_test,grid_tfdf_self.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_multinomialnb__alpha</th>\n",
       "      <th>param_tfidfvectorizer__max_features</th>\n",
       "      <th>param_tfidfvectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.519801</td>\n",
       "      <td>0.029804</td>\n",
       "      <td>0.160946</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>650</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'multinomialnb__alpha': 650, 'tfidfvectorizer...</td>\n",
       "      <td>0.755177</td>\n",
       "      <td>0.750305</td>\n",
       "      <td>0.726553</td>\n",
       "      <td>0.747259</td>\n",
       "      <td>0.755786</td>\n",
       "      <td>0.747016</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.524888</td>\n",
       "      <td>0.024791</td>\n",
       "      <td>0.102093</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>630</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'multinomialnb__alpha': 630, 'tfidfvectorizer...</td>\n",
       "      <td>0.761267</td>\n",
       "      <td>0.754568</td>\n",
       "      <td>0.720463</td>\n",
       "      <td>0.742996</td>\n",
       "      <td>0.755177</td>\n",
       "      <td>0.746894</td>\n",
       "      <td>0.014477</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.517871</td>\n",
       "      <td>0.028229</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>650</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'multinomialnb__alpha': 650, 'tfidfvectorizer...</td>\n",
       "      <td>0.761876</td>\n",
       "      <td>0.754568</td>\n",
       "      <td>0.720463</td>\n",
       "      <td>0.742996</td>\n",
       "      <td>0.754568</td>\n",
       "      <td>0.746894</td>\n",
       "      <td>0.014533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9        1.519801      0.029804         0.160946        0.006437   \n",
       "20       0.524888      0.024791         0.102093        0.006393   \n",
       "8        0.517871      0.028229         0.109900        0.007815   \n",
       "\n",
       "   param_multinomialnb__alpha param_tfidfvectorizer__max_features  \\\n",
       "9                         650                                5000   \n",
       "20                        630                                5000   \n",
       "8                         650                                5000   \n",
       "\n",
       "   param_tfidfvectorizer__ngram_range  \\\n",
       "9                              (1, 2)   \n",
       "20                             (1, 1)   \n",
       "8                              (1, 1)   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "9   {'multinomialnb__alpha': 650, 'tfidfvectorizer...           0.755177   \n",
       "20  {'multinomialnb__alpha': 630, 'tfidfvectorizer...           0.761267   \n",
       "8   {'multinomialnb__alpha': 650, 'tfidfvectorizer...           0.761876   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "9            0.750305           0.726553           0.747259   \n",
       "20           0.754568           0.720463           0.742996   \n",
       "8            0.754568           0.720463           0.742996   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "9            0.755786         0.747016        0.010706                1  \n",
       "20           0.755177         0.746894        0.014477                2  \n",
       "8            0.754568         0.746894        0.014533                2  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_tfdf_self.cv_results_).sort_values(by='rank_test_score').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation:\n",
    "\n",
    "Model Three is the best scoring model for selftext, performing slightly better than the other models on both accuracy and recall, with approximately 74% and 86% respectively. As I am aiming to optimize these parameters, I knew that this was the model I wanted to try and improve using the AdaBoost algorithm. There is a overfitting present in this model, which I want to see if it could be reduced with AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Four. TfidfVectorizer, LemmaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate tfidf vectorizer and pipeline\n",
    "tfdfNB_lemma = TfidfVectorizer(stop_words = stop_word,tokenizer = LemmaTokenizer())\n",
    "pipelemma_selftext = make_pipeline(tfdfNB_lemma, StandardScaler(with_mean=False),MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...],\n",
       "                                                        tokenizer=<__main__.LemmaTokenizer object at 0x00000276D2262970>)),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('multinomialnb', MultinomialNB())]),\n",
       "             param_grid={'multinomialnb__alpha': [635, 650, 645, 630],\n",
       "                         'tfidfvectorizer__max_features': [4750, 5000, 5250],\n",
       "                         'tfidfvectorizer__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate gridsearchCV values\n",
    "grid_tflemma = GridSearchCV(pipelemma_selftext,param_grid = param_tfdf_selftext)\n",
    "\n",
    "#fit gridsearch to training data\n",
    "grid_tflemma.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multinomialnb__alpha': 650,\n",
       " 'tfidfvectorizer__max_features': 5250,\n",
       " 'tfidfvectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best parameters for the gridsearch\n",
    "grid_tflemma.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_multinomialnb__alpha</th>\n",
       "      <th>param_tfidfvectorizer__max_features</th>\n",
       "      <th>param_tfidfvectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.981419</td>\n",
       "      <td>0.068977</td>\n",
       "      <td>0.868293</td>\n",
       "      <td>0.036444</td>\n",
       "      <td>650</td>\n",
       "      <td>5250</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'multinomialnb__alpha': 650, 'tfidfvectorizer...</td>\n",
       "      <td>0.758831</td>\n",
       "      <td>0.752741</td>\n",
       "      <td>0.736297</td>\n",
       "      <td>0.749086</td>\n",
       "      <td>0.755177</td>\n",
       "      <td>0.750426</td>\n",
       "      <td>0.007746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.937206</td>\n",
       "      <td>0.029469</td>\n",
       "      <td>0.862052</td>\n",
       "      <td>0.035466</td>\n",
       "      <td>645</td>\n",
       "      <td>5250</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'multinomialnb__alpha': 645, 'tfidfvectorizer...</td>\n",
       "      <td>0.758222</td>\n",
       "      <td>0.752741</td>\n",
       "      <td>0.736297</td>\n",
       "      <td>0.749086</td>\n",
       "      <td>0.755177</td>\n",
       "      <td>0.750305</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.892781</td>\n",
       "      <td>0.044819</td>\n",
       "      <td>0.858433</td>\n",
       "      <td>0.035940</td>\n",
       "      <td>635</td>\n",
       "      <td>5250</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'multinomialnb__alpha': 635, 'tfidfvectorizer...</td>\n",
       "      <td>0.758222</td>\n",
       "      <td>0.753350</td>\n",
       "      <td>0.735079</td>\n",
       "      <td>0.749086</td>\n",
       "      <td>0.755177</td>\n",
       "      <td>0.750183</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11       3.981419      0.068977         0.868293        0.036444   \n",
       "17       3.937206      0.029469         0.862052        0.035466   \n",
       "5        3.892781      0.044819         0.858433        0.035940   \n",
       "\n",
       "   param_multinomialnb__alpha param_tfidfvectorizer__max_features  \\\n",
       "11                        650                                5250   \n",
       "17                        645                                5250   \n",
       "5                         635                                5250   \n",
       "\n",
       "   param_tfidfvectorizer__ngram_range  \\\n",
       "11                             (1, 2)   \n",
       "17                             (1, 2)   \n",
       "5                              (1, 2)   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "11  {'multinomialnb__alpha': 650, 'tfidfvectorizer...           0.758831   \n",
       "17  {'multinomialnb__alpha': 645, 'tfidfvectorizer...           0.758222   \n",
       "5   {'multinomialnb__alpha': 635, 'tfidfvectorizer...           0.758222   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "11           0.752741           0.736297           0.749086   \n",
       "17           0.752741           0.736297           0.749086   \n",
       "5            0.753350           0.735079           0.749086   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "11           0.755177         0.750426        0.007746                1  \n",
       "17           0.755177         0.750305        0.007616                2  \n",
       "5            0.755177         0.750183        0.008111                3  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cast the results of the grid to a dataframe\n",
    "pd.DataFrame(grid_tflemma.cv_results_).sort_values(by='rank_test_score').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7398611618560468"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score on the test data\n",
    "grid_tflemma.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8258221680876979"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score on the training set\n",
    "grid_tflemma.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive Bayes model with TfidfVectorization & Lemmatization is 0.7399.\n",
      "The recall of the Naive Bayes model with TfidfVectorization & Lemmatization is 0.8617.\n",
      "The f1 score of the Naive Bayes model with TfidfVectorization & Lemmatization is 0.7901.\n",
      "The precision score of the Naive Bayes model with TfidfVectorization & Lemmatization is 0.7295.\n"
     ]
    }
   ],
   "source": [
    "#score on different classification metrics\n",
    "print(f'The accuracy of the Naive Bayes model with TfidfVectorization & Lemmatization is {round(grid_tflemma.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Naive Bayes model with TfidfVectorization & Lemmatization is {round(recall_score(y_test,grid_tflemma.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Naive Bayes model with TfidfVectorization & Lemmatization is {round(f1_score(y_test,grid_tflemma.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Naive Bayes model with TfidfVectorization & Lemmatization is {round(precision_score(y_test,grid_tflemma.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation.\n",
    "\n",
    "The TfidfVectorization with Lemmatization Model scores the same as the TfidfVectorization Model without Lemmatization, though the Lemmatized Model 4 contains no overfitting. Therefore we have more confidence in the coefficients and stability of Model Four, than compared to Model 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>protein</th>\n",
       "      <td>-7.493425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>-7.544414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ha</th>\n",
       "      <td>-7.587363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lab</th>\n",
       "      <td>-7.592660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doe</th>\n",
       "      <td>-7.600065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>-7.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <td>-7.663086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>-7.677455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acid</th>\n",
       "      <td>-7.682536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>-7.703733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enzyme</th>\n",
       "      <td>-7.705682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coefs\n",
       "protein  -7.493425\n",
       "year     -7.544414\n",
       "ha       -7.587363\n",
       "lab      -7.592660\n",
       "doe      -7.600065\n",
       "work     -7.646900\n",
       "question -7.663086\n",
       "school   -7.677455\n",
       "acid     -7.682536\n",
       "time     -7.703733\n",
       "enzyme   -7.705682"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grabbing the most important words from tfidf with lemmatization\n",
    "coefs_lemma = grid_tflemma.best_estimator_.named_steps['multinomialnb'].coef_\n",
    "words_lemma = grid_tflemma.best_estimator_.named_steps['tfidfvectorizer'].get_feature_names()\n",
    "coefs_lemma = pd.DataFrame({'coefs':coefs_lemma[0]}, \n",
    "                       index = words_lemma)\n",
    "coefs_lemma.nlargest(11,'coefs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The small dataframe above shows the largest/most important words for predicting the binary classification of r/biochemistry or r/biology. We can see that there are several biochemistry specific words at the top of this list, such as protien, enzyme and acid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2 frighteningly</th>\n",
       "      <td>-8.858938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 retrained</th>\n",
       "      <td>-8.858938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463053892</th>\n",
       "      <td>-8.858938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 foot</th>\n",
       "      <td>-8.858938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acting questionanswering</th>\n",
       "      <td>-8.858938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adblocker</th>\n",
       "      <td>-8.858938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adblocker pending</th>\n",
       "      <td>-8.858938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adventure game</th>\n",
       "      <td>-8.858938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai chat</th>\n",
       "      <td>-8.858938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai context</th>\n",
       "      <td>-8.858938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             coefs\n",
       "2 frighteningly          -8.858938\n",
       "2 retrained              -8.858938\n",
       "463053892                -8.858938\n",
       "5 foot                   -8.858938\n",
       "acting questionanswering -8.858938\n",
       "adblocker                -8.858938\n",
       "adblocker pending        -8.858938\n",
       "adventure game           -8.858938\n",
       "ai chat                  -8.858938\n",
       "ai context               -8.858938"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grabbing the words with the least impact on biochemistry classification\n",
    "coefs_lemma.nsmallest(10,'coefs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The small dataframe above shows the smallest/least important words for predicting the binary classification problem. We can see that these words, in alphabetical order (with numbers before letters), consist of spam/ad type words, such as ai chat or adventure game which have a significant presence in the r/biology subreddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Text Columns Modeling with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Modeling Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the combined text csv\n",
    "combined = pd.read_csv('datasets/combined_title_self.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22014 entries, 0 to 22013\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  22014 non-null  object\n",
      " 1   text       21943 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 516.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#shows that there are null values in the datafile\n",
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the null values from the dataframe\n",
    "combined.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21943, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the number of observations for the combined dataframe\n",
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all words that apply to the target variable -- biology,bio,biochem,biochemistry\n",
    "combined['text'].replace('biology','',regex=True,inplace=True)\n",
    "combined['text'].replace('biochemistry','',regex=True,inplace=True)\n",
    "combined['text'].replace('chemistry','',regex=True,inplace=True)\n",
    "combined['text'].replace('biochem','',regex=True,inplace=True)\n",
    "combined['text'].replace('bio','',regex=True,inplace=True)\n",
    "combined['text'].replace('chem','',regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up initial X and y values\n",
    "#1 corresponds to biochemistry, 0 corresponds to biology\n",
    "#need to make the str unicode with astype, emoji characters in the strings\n",
    "#help with the unicode error found below:\n",
    "#https://stackoverflow.com/questions/39303912/tfidfvectorizer-in-scikit-learn-valueerror-np-nan-is-an-invalid-document\n",
    "X_combo = combined['text']\n",
    "y = np.where(combined['subreddit']=='Biochemistry',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split of the data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_combo,y,stratify=y,random_state=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count vectorize words to find the most common\n",
    "cvect_selftext = CountVectorizer()\n",
    "Xcombo_selftext = cvect_selftext.fit_transform(X_combo)\n",
    "#make it a dataframe\n",
    "dtm_combo = pd.DataFrame(Xcombo_selftext.toarray(),columns = cvect_selftext.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make a graph of the most common words\n",
    "dtm_combo.sum().sort_values(ascending=False).head(10).plot(kind='bar',\n",
    "                                                              figsize=(12,7),\n",
    "                                                             color='#9370DB')\n",
    "plt.xlabel('Word',fontsize=12),\n",
    "plt.ylabel('Word Count',fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.title('The 10 Most Common Words in Combined Reddit Text',fontsize=12)\n",
    "plt.savefig('images/most_common.png',bbox_inches='tight', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Interpretation:\n",
    "\n",
    "The graph above shows the 10 most common words in the selftext/body of the subreddits posts from r/biology and r/biochemistry. As you can see, a majority of the most common words are prepositions - words such as the, to, in, etc. These prepositional words do not have any significant meaning to predicting whether a post will more likely be in r/biology or r/biochemistry so they will be removed from the models with the stop_words parameter in either CountVetorizer or TfidfVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model for Combined Text Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent class is r/biochemistry. The accuracy of the null model is 0.5673.\n"
     ]
    }
   ],
   "source": [
    "#to get the baseline accuracy of the model\n",
    "#based on the most frequent value in the training data\n",
    "#biochemistry = 1, biology = 0\n",
    "\n",
    "biochem_num = y_train.sum()\n",
    "biology_num = len(y_train)-biochem_num\n",
    "\n",
    "if biology_num < biochem_num:\n",
    "    baseline_accur = round(biochem_num/len(y_train),4)\n",
    "    print(f'The most frequent class is r/biochemistry. The accuracy of the null model is {baseline_accur}.')\n",
    "    \n",
    "else:\n",
    "    baseline_accuracy = round((biology_num)/len(y_train),4)\n",
    "    print(f'The most frequent class is r/biology. The accuracy of the null model is {baseline_accuracy}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline/Null Model Explained:\n",
    "\n",
    "The baseline model allows us to find a 'starting point' to compare the performance of future models to. In binary classification, a customary baseline/null model is one that will guess the most frequently occuring class in the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model One. CountVectorizer, Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipeline for Naive Bayes modeling with selftext\n",
    "cvect_combo= CountVectorizer(stop_words=stop_word)\n",
    "pipeNB_combo = make_pipeline(cvect_combo, StandardScaler(with_mean=False), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the parameter grid for the gridsearchCV\n",
    "param_combo = {\n",
    "    'countvectorizer__max_features': [5_500,6_000,5_250],\n",
    "    'countvectorizer__ngram_range':[(1,1),(1,2)],\n",
    "    'multinomialnb__alpha':[750,800,825,900]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                        CountVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...])),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('multinomialnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'countvectorizer__max_features': [5500, 6000, 5250],\n",
       "                         'countvectorizer__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'multinomialnb__alpha': [750, 800, 825, 900]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the gridsearch instance\n",
    "grid_combo = GridSearchCV(pipeNB_combo,param_grid=param_combo,n_jobs=-1)\n",
    "\n",
    "#fit the training data to the gridsearch\n",
    "grid_combo.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__max_features': 6000,\n",
       " 'countvectorizer__ngram_range': (1, 1),\n",
       " 'multinomialnb__alpha': 800}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best parameters\n",
    "grid_combo.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's predictions on the first ten observations in the testing data [0 1 1 1 0 0 0 0 0 1].\n",
      "The true values of the first ten observations in the testing data [1 1 1 1 0 1 0 0 1 1].\n",
      "__________________________________________________________________________________\n",
      "\n",
      "The text that corresponds to the first ten observations in the testing data: \n",
      " 16245    hi question about amoxicillin and gramnegative...\n",
      "20641    quick basic question on net charge of peptides...\n",
      "5353                                              help plz\n",
      "20904               what path did you take after your  bsc\n",
      "375      i was looking to find out how the speed of ele...\n",
      "10711    are there any examples of combining crisprcas9...\n",
      "15407                                    dissection videos\n",
      "3435     suppose you have a time machine and the cycle ...\n",
      "21477    obscure question why does saliva cause things ...\n",
      "6127     i would like to make a quality presentation on...\n",
      "Name: text, dtype: object.\n"
     ]
    }
   ],
   "source": [
    "#the predictions for grid_combo on the test/holdout data\n",
    "print(f\"The model's predictions on the first ten observations in the testing data {grid_combo.predict(X_test)[:10]}.\")\n",
    "print(f\"The true values of the first ten observations in the testing data {y_test[:10]}.\")\n",
    "print('__________________________________________________________________________________')\n",
    "print('')\n",
    "print(f\"The text that corresponds to the first ten observations in the testing data: \\n {X_test[:10]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions Comparison\n",
    "\n",
    "In the above true test values and predictions made by the model, we can see that the model can correctly predict differences in scientitic terminology. The two posts I want to draw attention to are:\n",
    "\n",
    "'cargo transport in our cells dynein', which is correctly classified as an r/biochemistry post and 'what could happen if the cells could survive a day longer in the body' which is correctly classified as a r/biology post. Though both posts have to do with cells, the model is correctly able to classify the other terminology correctly and predict microscopic level differences between biology and biochemistry based on terminology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7841647930971622"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scoring on the training data\n",
    "grid_combo.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive Bayes model with combined text is 0.7457.\n",
      "The recall of the Naive Bayes model with combined text is 0.8541.\n",
      "The f1 score of the Naive Bayes model with combined text is 0.7921.\n",
      "The precision score of the Naive Bayes model with combined text is 0.7385.\n"
     ]
    }
   ],
   "source": [
    "#score on different classification metrics\n",
    "print(f'The accuracy of the Naive Bayes model with combined text is {round(grid_combo.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Naive Bayes model with combined text is {round(recall_score(y_test,grid_combo.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Naive Bayes model with combined text is {round(f1_score(y_test,grid_combo.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Naive Bayes model with combined text is {round(precision_score(y_test,grid_combo.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_countvectorizer__ngram_range</th>\n",
       "      <th>param_multinomialnb__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.591342</td>\n",
       "      <td>0.011519</td>\n",
       "      <td>0.123315</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>6000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>800</td>\n",
       "      <td>{'countvectorizer__max_features': 6000, 'count...</td>\n",
       "      <td>0.734812</td>\n",
       "      <td>0.737849</td>\n",
       "      <td>0.750836</td>\n",
       "      <td>0.742024</td>\n",
       "      <td>0.729262</td>\n",
       "      <td>0.738956</td>\n",
       "      <td>0.007251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.609566</td>\n",
       "      <td>0.029373</td>\n",
       "      <td>0.131325</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>6000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>825</td>\n",
       "      <td>{'countvectorizer__max_features': 6000, 'count...</td>\n",
       "      <td>0.734204</td>\n",
       "      <td>0.737849</td>\n",
       "      <td>0.750836</td>\n",
       "      <td>0.742328</td>\n",
       "      <td>0.728654</td>\n",
       "      <td>0.738774</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.587750</td>\n",
       "      <td>0.034669</td>\n",
       "      <td>0.131319</td>\n",
       "      <td>0.018644</td>\n",
       "      <td>6000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>750</td>\n",
       "      <td>{'countvectorizer__max_features': 6000, 'count...</td>\n",
       "      <td>0.735115</td>\n",
       "      <td>0.737849</td>\n",
       "      <td>0.750836</td>\n",
       "      <td>0.741720</td>\n",
       "      <td>0.728350</td>\n",
       "      <td>0.738774</td>\n",
       "      <td>0.007444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9        0.591342      0.011519         0.123315        0.002790   \n",
       "10       0.609566      0.029373         0.131325        0.004530   \n",
       "8        0.587750      0.034669         0.131319        0.018644   \n",
       "\n",
       "   param_countvectorizer__max_features param_countvectorizer__ngram_range  \\\n",
       "9                                 6000                             (1, 1)   \n",
       "10                                6000                             (1, 1)   \n",
       "8                                 6000                             (1, 1)   \n",
       "\n",
       "   param_multinomialnb__alpha  \\\n",
       "9                         800   \n",
       "10                        825   \n",
       "8                         750   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "9   {'countvectorizer__max_features': 6000, 'count...           0.734812   \n",
       "10  {'countvectorizer__max_features': 6000, 'count...           0.734204   \n",
       "8   {'countvectorizer__max_features': 6000, 'count...           0.735115   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "9            0.737849           0.750836           0.742024   \n",
       "10           0.737849           0.750836           0.742328   \n",
       "8            0.737849           0.750836           0.741720   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "9            0.729262         0.738956        0.007251                1  \n",
       "10           0.728654         0.738774        0.007514                2  \n",
       "8            0.728350         0.738774        0.007444                3  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe of grid results\n",
    "pd.DataFrame(grid_combo.cv_results_).sort_values(by='rank_test_score').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation\n",
    "\n",
    "Model One of combined title and selftext similarly as Model Three of Selftext, the only significant difference is that Model One contains no overfitting - as the accuracy of the training score is very close to the accuracy of the testing data. This makes the Model One of combined text more stable in coefficient values and makes us more confident in it's performance as a predictor.\n",
    "\n",
    "This model was chosen as the final model for several reasons: it has one of the highest pair-wise scores for accuracy and recall, and is not overfit. Many other models that scored similarly to this model contained overfitting/high variance. The lack of variance in this model makes me more confident that it is a more stable predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create graph of the most important words for classifying something as biochemistry\n",
    "coefs0 = grid_combo.best_estimator_.named_steps['multinomialnb'].coef_\n",
    "words0 = grid_combo.best_estimator_.named_steps['countvectorizer'].get_feature_names()\n",
    "coefs0 = pd.DataFrame({'coefs':coefs0[0]}, \n",
    "                       index = words0).nlargest(10,'coefs')\n",
    "#manipulation and creation of the graph\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(x = coefs0.index,height = coefs0['coefs'],color='#FA8072')\n",
    "plt.title('10 Largest Values in Word Importance',fontsize=12)\n",
    "plt.xlabel('Word',fontsize=12)\n",
    "plt.ylabel('Coefficient',fontsize=12)\n",
    "plt.xticks(rotation=30,fontsize=12)\n",
    "plt.savefig('images/largest_coefs.png',bbox_inches='tight', dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Interpretation\n",
    "\n",
    "The above visualization shows 10 most important words for classifying a post for r/biochemistry. These words had the highest coefficients, as they are negative the lowest negative number will be the largest, and where therefore deemed the most important features. Many of the posts in r/biochemistrywere not scientific questions as I thought, but were advice posts - asking about the best schools to get a biochemistry degree, etc. In this case, it makes sense that some of these words would appear within the most important words, such as the word question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create graph of the most important words for classifying something as biochemistry\n",
    "coefs1 = grid_combo.best_estimator_.named_steps['multinomialnb'].coef_\n",
    "words1 = grid_combo.best_estimator_.named_steps['countvectorizer'].get_feature_names()\n",
    "coefs1 = pd.DataFrame({'coefs':coefs1[0]}, \n",
    "                       index = words1).nsmallest(10,'coefs')\n",
    "#manipulation and creation of the graph\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(x = coefs1.index,height = coefs1['coefs'],color='#FA8072')\n",
    "plt.title('Smallest Values in Word Importance for r/Biochemistry')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig('images/smallest_coefs.png',bbox_inches='tight', dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Interpretation\n",
    "\n",
    "The above visualization shows a sampling of the most important words in classfying a post as being from r/biology. These words show that there are several biology terms and some spam that was prevalent within the r/biology subreddit. 40x signifies the 40 times magnification of an objective of a microscope, which in turn results in 400x magnification (10x ocular).\n",
    "\n",
    "These words are in alphebetical order and there are approximately 200 words which have this same coefficient value, but many aren't shown in the above visualization.Many biology terms made this list: gametes, fitness, phylogenetic tree, meiosis, oocytes, to name a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40x</th>\n",
       "      <td>-9.034324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-9.034324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>-9.034324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptation</th>\n",
       "      <td>-9.034324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptations</th>\n",
       "      <td>-9.034324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wound</th>\n",
       "      <td>-9.034324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xylem</th>\n",
       "      <td>-9.034324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>-9.034324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lockdown</th>\n",
       "      <td>-9.022726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mask</th>\n",
       "      <td>-9.021686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                coefs\n",
       "40x         -9.034324\n",
       "48          -9.034324\n",
       "abandoned   -9.034324\n",
       "adaptation  -9.034324\n",
       "adaptations -9.034324\n",
       "...               ...\n",
       "wound       -9.034324\n",
       "xylem       -9.034324\n",
       "zoo         -9.034324\n",
       "lockdown    -9.022726\n",
       "mask        -9.021686\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grabbing the most important words from tfidf with lemmatization\n",
    "coefs_comb = grid_combo.best_estimator_.named_steps['multinomialnb'].coef_\n",
    "words_comb = grid_combo.best_estimator_.named_steps['countvectorizer'].get_feature_names()\n",
    "coefs_comb = pd.DataFrame({'coefs':coefs_comb[0]}, \n",
    "                       index = words_comb)\n",
    "coefs_comb.nsmallest(200,'coefs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The above small dataframe show the smallest coefficient values of the final production model. Aproximately 200 words were the least important to classifying the r/biochemistry subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix of the values\n",
    "plot_confusion_matrix(grid_combo,X_test,y_test)\n",
    "plt.title('Confusion Matrix of the Final Model');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Above is a confusion matrix of the final production model, Model One with CountVectorization and MultinomialNB estimator. In the visualization 1 corresponds to r/biochemistry and 0 corresponds to r/biology. The top left corner represents the false positive values, as you can see about 2/3 of the misclassifications the model made are actually false positives (r/biology posts being classified as r/biochemistry posts). This is important to note, as we are trying to optimize recall. This big error in false positive misclassification may be do to the more general nature of the r/biology posts, and have less differentiable words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Two. TfidfVectorization with Naive Bayes for Combined Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate tfidf vectorizer and pipeline\n",
    "tfdfNB_combo = TfidfVectorizer(stop_words = stop_word)\n",
    "pipeNBtddf_combo = make_pipeline(tfdfNB_combo, StandardScaler(with_mean=False),MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter grid for TfidfVectorizer and Bayes with combined text\n",
    "param_tfdf_combo = {\n",
    "    'tfidfvectorizer__max_features': [5_000,6_000],\n",
    "    'tfidfvectorizer__ngram_range':[(1,1),(1,2),(2,2)],\n",
    "    'multinomialnb__alpha':[1,10,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...])),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('multinomialnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'multinomialnb__alpha': [1, 10, 5],\n",
       "                         'tfidfvectorizer__max_features': [5000, 6000],\n",
       "                         'tfidfvectorizer__ngram_range': [(1, 1), (1, 2),\n",
       "                                                          (2, 2)]})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create gridsearch for combined text with tfidfvectorization\n",
    "grid_combo_tfdf = GridSearchCV(pipeNBtddf_combo,param_grid = param_tfdf_combo,n_jobs=-1)\n",
    "\n",
    "#fit the grid to the training data\n",
    "grid_combo_tfdf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8042250956109999"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score accuracy on the training data\n",
    "grid_combo_tfdf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multinomialnb__alpha': 10,\n",
       " 'tfidfvectorizer__max_features': 5000,\n",
       " 'tfidfvectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best parameters\n",
    "grid_combo_tfdf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive Bayes model with combined text is 0.7294.\n",
      "The recall of the Naive Bayes model with combined text is 0.7934.\n",
      "The f1 score of the Naive Bayes model with combined text is 0.7687.\n",
      "The precision score of the Naive Bayes model with combined text is 0.7455.\n"
     ]
    }
   ],
   "source": [
    "#score on different classification metrics\n",
    "print(f'The accuracy of the Naive Bayes model with combined text is {round(grid_combo_tfdf.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Naive Bayes model with combined text is {round(recall_score(y_test,grid_combo_tfdf.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Naive Bayes model with combined text is {round(f1_score(y_test,grid_combo_tfdf.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Naive Bayes model with combined text is {round(precision_score(y_test,grid_combo_tfdf.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation:\n",
    "\n",
    "The TfidfVectorization with the combined text performed several percentage points worse in the recall metric and had slightly more overfitting than Model One with combined text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing all of the text values together - seltext, title, and the combined text - I discovered that selftext and combined title+selftext coincided with similar model scores in accuracy and recall. Although, the combined text column scored better with 75% accuracy and 86% recall, without overfitting. Combining the selftext and title data and ultimately producing more data for a model to train on reduces the variance of the models produced, leading to more stable models we can have higher confidence in."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
