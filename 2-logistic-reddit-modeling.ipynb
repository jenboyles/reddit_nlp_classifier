{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification Modeling - r/biology & r/biochemistry Predicting with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, balanced_accuracy_score\n",
    "\n",
    "#lemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Import stemmer.\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# Import RegEx Tokenizer\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the submissions csv file\n",
    "#get rid of unnamed:0 column wtih index_col\n",
    "submissions = pd.read_csv('datasets/cleaned-submission.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6227</th>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>so far ive mostly looked for stuff in my homet...</td>\n",
       "      <td>wanting to take a year off between undergrad a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6228</th>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>im currently taking a biochemistry class at un...</td>\n",
       "      <td>biochemistry help</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                           selftext  \\\n",
       "6227  Biochemistry  so far ive mostly looked for stuff in my homet...   \n",
       "6228  Biochemistry  im currently taking a biochemistry class at un...   \n",
       "\n",
       "                                                  title  \n",
       "6227  wanting to take a year off between undergrad a...  \n",
       "6228                                  biochemistry help  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#observing the last two models\n",
    "submissions.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all words that apply to the target variable -- biology,bio,biochem,biochemistry\n",
    "submissions['selftext'].replace('biology','',regex=True,inplace=True)\n",
    "submissions['selftext'].replace('biochemistry','',regex=True,inplace=True)\n",
    "submissions['selftext'].replace('chemistry','',regex=True,inplace=True)\n",
    "submissions['selftext'].replace('biochem','',regex=True,inplace=True)\n",
    "submissions['selftext'].replace('bio','',regex=True,inplace=True)\n",
    "submissions['selftext'].replace('chem','',regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing any null rows\n",
    "submissions.dropna(how='any',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit    0\n",
       "selftext     0\n",
       "title        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look for null values\n",
    "submissions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6227</th>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>so far ive mostly looked for stuff in my homet...</td>\n",
       "      <td>wanting to take a year off between undergrad a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6228</th>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>im currently taking a  class at university im ...</td>\n",
       "      <td>biochemistry help</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                           selftext  \\\n",
       "6227  Biochemistry  so far ive mostly looked for stuff in my homet...   \n",
       "6228  Biochemistry  im currently taking a  class at university im ...   \n",
       "\n",
       "                                                  title  \n",
       "6227  wanting to take a year off between undergrad a...  \n",
       "6228                                  biochemistry help  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to make sure word drop occurred correctly\n",
    "submissions.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step over collection of tokens and try to lemmatize each of them\n",
    "#to use in countvectorizer we pass the new class as the tokenizer\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    def __call__(self,doc):\n",
    "        return [self.lemmatizer.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step over collection of word tokens and stemmatize\n",
    "#create a class to pass into Countvectorizer in a pipeline\n",
    "class StemTokenizer:\n",
    "    def __init__(self):\n",
    "        self.stemmatizer = PorterStemmer()\n",
    "    def __call__(self,doc):\n",
    "        return [self.stemmatizer.stem(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#longer list of stop words\n",
    "#taken from the open source work found here: https://gist.github.com/sebleier/554280\n",
    "#txt found here: https://gist.githubusercontent.com/ZohebAbai/513218c3468130eacff6481f424e4e64/raw/b70776f341a148293ff277afa0d0302c8c38f7e2/gist_stopwords.txt\n",
    "\n",
    "stop_word = pd.read_csv('datasets/stopwords.csv',index_col=0)\n",
    "stop_word = list(stop_word['stopwords'])\n",
    "\n",
    "#remove punctuation from the stop words, as it has already been done in cleaning the text\n",
    "stop_word = [word.replace(\"'\",'') for word in stop_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Modeling With Selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up X and y values for modeling\n",
    "X = submissions['selftext']\n",
    "y = np.where(submissions['subreddit']=='Biochemistry',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split the data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,random_state = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent class is r/biochemistry. The accuracy of the null model is 0.5686.\n"
     ]
    }
   ],
   "source": [
    "#to get the baseline accuracy of the model\n",
    "#based on the most frequent value in the training data\n",
    "#biochemistry = 1, biology = 0\n",
    "\n",
    "biochem_num = y_train.sum()\n",
    "biology_num = len(y_train)-biochem_num\n",
    "\n",
    "if biology_num < biochem_num:\n",
    "    baseline_accur = round(biochem_num/len(y_train),4)\n",
    "    print(f'The most frequent class is r/biochemistry. The accuracy of the null model is {baseline_accur}.')\n",
    "    \n",
    "else:\n",
    "    baseline_accuracy = round((biology_num)/len(y_train),4)\n",
    "    print(f'The most frequent class is r/biology. The accuracy of the null model is {baseline_accuracy}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline/Null Model Explained:\n",
    "\n",
    "The baseline model allows us to find a 'starting point' to compare the performance of future models to. In binary classification, a customary baseline/null model is one that will guess the most frequently occuring class in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with CountVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model One. Basic Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make logistic pipeline\n",
    "cvect = CountVectorizer(stop_words = stop_word)\n",
    "pipe = make_pipeline(cvect,StandardScaler(with_mean=False),LogisticRegression(max_iter=10_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(stop_words=['0o', '0s', '3a', '3b', '3d', '6b',\n",
       "                                             '6o', 'a', 'a1', 'a2', 'a3', 'a4',\n",
       "                                             'ab', 'able', 'about', 'above',\n",
       "                                             'abst', 'ac', 'accordance',\n",
       "                                             'according', 'accordingly',\n",
       "                                             'across', 'act', 'actually', 'ad',\n",
       "                                             'added', 'adj', 'ae', 'af',\n",
       "                                             'affected', ...])),\n",
       "                ('standardscaler', StandardScaler(with_mean=False)),\n",
       "                ('logisticregression', LogisticRegression(max_iter=10000))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit training data to the logistic regression pipe\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9953714981729598"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score on training data\n",
    "pipe.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression model is 0.6558.\n",
      "The recall of the Logistic Regression model is 0.6842.\n",
      "The f1 score of the Logistic Regression model is 0.6932.\n",
      "The precision score of the Logistic Regression model is 0.7023.\n"
     ]
    }
   ],
   "source": [
    "#scores on the different classification metrics\n",
    "print(f'The accuracy of the Logistic Regression model is {round(pipe.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Logistic Regression model is {round(recall_score(y_test,pipe.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Logistic Regression model is {round(f1_score(y_test,pipe.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Logistic Regression model is {round(precision_score(y_test,pipe.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation\n",
    "\n",
    "Model One is a 'default' model, without hyperparameter tuning. Comparing the accuracy on the training data and the testing data show that it is highly overfit. This high variance makes the model poor at generalizing, corresponding to the low accuracy score of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Two. GridSearchCV Basic Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter grid for gridsearch\n",
    "param_log = {\n",
    "    'countvectorizer__max_features':[2_950,3_000,3_050],\n",
    "    'countvectorizer__ngram_range': [(1,1),(1,2)],\n",
    "    'logisticregression__C': [.0001,.001,.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                        CountVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...])),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'countvectorizer__max_features': [2950, 3000, 3050],\n",
       "                         'countvectorizer__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'logisticregression__C': [0.0001, 0.001, 0.1]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate gridsearch for logistic regression\n",
    "grid_log = GridSearchCV(pipe,param_grid=param_log,n_jobs=-1)\n",
    "\n",
    "#fit training data to the gridsearch\n",
    "grid_log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8490864799025578"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score on the training data\n",
    "grid_log.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression model is 0.7231.\n",
      "The recall of the Logistic Regression model is 0.8367.\n",
      "The f1 score of the Logistic Regression model is 0.7744.\n",
      "The precision score of the Logistic Regression model is 0.7208.\n"
     ]
    }
   ],
   "source": [
    "#score on the classification metrics\n",
    "print(f'The accuracy of the Logistic Regression model is {round(grid_log.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Logistic Regression model is {round(recall_score(y_test,grid_log.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Logistic Regression model is {round(f1_score(y_test,grid_log.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Logistic Regression model is {round(precision_score(y_test,grid_log.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__max_features': 2950,\n",
       " 'countvectorizer__ngram_range': (1, 2),\n",
       " 'logisticregression__C': 0.001}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the best parameters\n",
    "grid_log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_countvectorizer__ngram_range</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.191170</td>\n",
       "      <td>0.422920</td>\n",
       "      <td>0.401769</td>\n",
       "      <td>0.042739</td>\n",
       "      <td>2950</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 2950, 'count...</td>\n",
       "      <td>0.738733</td>\n",
       "      <td>0.732643</td>\n",
       "      <td>0.719854</td>\n",
       "      <td>0.734470</td>\n",
       "      <td>0.721681</td>\n",
       "      <td>0.729476</td>\n",
       "      <td>0.007403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.855334</td>\n",
       "      <td>0.047171</td>\n",
       "      <td>0.398162</td>\n",
       "      <td>0.008849</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 3000, 'count...</td>\n",
       "      <td>0.738733</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>0.717418</td>\n",
       "      <td>0.735079</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.728502</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.745006</td>\n",
       "      <td>0.076847</td>\n",
       "      <td>0.355723</td>\n",
       "      <td>0.051313</td>\n",
       "      <td>3050</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 3050, 'count...</td>\n",
       "      <td>0.736906</td>\n",
       "      <td>0.728380</td>\n",
       "      <td>0.719245</td>\n",
       "      <td>0.732643</td>\n",
       "      <td>0.722899</td>\n",
       "      <td>0.728015</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.532263</td>\n",
       "      <td>0.230686</td>\n",
       "      <td>0.273455</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>2950</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 2950, 'count...</td>\n",
       "      <td>0.733252</td>\n",
       "      <td>0.724726</td>\n",
       "      <td>0.718027</td>\n",
       "      <td>0.732643</td>\n",
       "      <td>0.726553</td>\n",
       "      <td>0.727040</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.371288</td>\n",
       "      <td>0.012910</td>\n",
       "      <td>0.276636</td>\n",
       "      <td>0.028729</td>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 3000, 'count...</td>\n",
       "      <td>0.730816</td>\n",
       "      <td>0.718636</td>\n",
       "      <td>0.718636</td>\n",
       "      <td>0.732643</td>\n",
       "      <td>0.725944</td>\n",
       "      <td>0.725335</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4        4.191170      0.422920         0.401769        0.042739   \n",
       "10       3.855334      0.047171         0.398162        0.008849   \n",
       "16       3.745006      0.076847         0.355723        0.051313   \n",
       "1        1.532263      0.230686         0.273455        0.046300   \n",
       "7        1.371288      0.012910         0.276636        0.028729   \n",
       "\n",
       "   param_countvectorizer__max_features param_countvectorizer__ngram_range  \\\n",
       "4                                 2950                             (1, 2)   \n",
       "10                                3000                             (1, 2)   \n",
       "16                                3050                             (1, 2)   \n",
       "1                                 2950                             (1, 1)   \n",
       "7                                 3000                             (1, 1)   \n",
       "\n",
       "   param_logisticregression__C  \\\n",
       "4                        0.001   \n",
       "10                       0.001   \n",
       "16                       0.001   \n",
       "1                        0.001   \n",
       "7                        0.001   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "4   {'countvectorizer__max_features': 2950, 'count...           0.738733   \n",
       "10  {'countvectorizer__max_features': 3000, 'count...           0.738733   \n",
       "16  {'countvectorizer__max_features': 3050, 'count...           0.736906   \n",
       "1   {'countvectorizer__max_features': 2950, 'count...           0.733252   \n",
       "7   {'countvectorizer__max_features': 3000, 'count...           0.730816   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "4            0.732643           0.719854           0.734470   \n",
       "10           0.727162           0.717418           0.735079   \n",
       "16           0.728380           0.719245           0.732643   \n",
       "1            0.724726           0.718027           0.732643   \n",
       "7            0.718636           0.718636           0.732643   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "4            0.721681         0.729476        0.007403                1  \n",
       "10           0.724117         0.728502        0.007640                2  \n",
       "16           0.722899         0.728015        0.006383                3  \n",
       "1            0.726553         0.727040        0.005600                4  \n",
       "7            0.725944         0.725335        0.005892                5  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make the results of the gridsearch into a dataframe\n",
    "pd.DataFrame(grid_log.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation\n",
    "\n",
    "Model Two, a hyperparameter tuning of Model One, improved the default to 72.3% accuracy and 84% recall. This model still shows overfitting, with a training score of 85% accuracy and testing score of 72.3%. This overfitting corresponds to low generalization ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Three. GridsearchCV, LemmaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make logistic pipeline\n",
    "cvect_lemma = CountVectorizer(stop_words = stop_word,tokenizer=LemmaTokenizer())\n",
    "pipe_lemma = make_pipeline(cvect_lemma,StandardScaler(with_mean=False),LogisticRegression(max_iter=10_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter grid for gridsearch\n",
    "param_log = {\n",
    "    'countvectorizer__max_features':[3_500,4_000,5_500],\n",
    "    'countvectorizer__ngram_range': [(1,1),(1,2)],\n",
    "    'logisticregression__C': [.0001,.001,.1,1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                        CountVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...],\n",
       "                                                        tokenizer=<__main__.LemmaTokenizer object at 0x0000026F87E163A0>)),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'countvectorizer__max_features': [3500, 4000, 5500],\n",
       "                         'countvectorizer__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'logisticregression__C': [0.0001, 0.001, 0.1, 1]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate grid search over lemmatokenizer\n",
    "grid_lemma = GridSearchCV(pipe_lemma,param_grid=param_log,n_jobs=-1)\n",
    "\n",
    "#fit training data to the grid\n",
    "grid_lemma.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861510353227771"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lemma.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression model is 0.7282.\n",
      "The recall of the Logistic Regression model is 0.8386.\n",
      "The f1 score of the Logistic Regression model is 0.778.\n",
      "The precision score of the Logistic Regression model is 0.7257.\n"
     ]
    }
   ],
   "source": [
    "#score on the classification metrics\n",
    "print(f'The accuracy of the Logistic Regression model is {round(grid_lemma.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Logistic Regression model is {round(recall_score(y_test,grid_lemma.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Logistic Regression model is {round(f1_score(y_test,grid_lemma.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Logistic Regression model is {round(precision_score(y_test,grid_lemma.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_countvectorizer__ngram_range</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.696713</td>\n",
       "      <td>0.973825</td>\n",
       "      <td>3.762837</td>\n",
       "      <td>0.101393</td>\n",
       "      <td>3500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 3500, 'count...</td>\n",
       "      <td>0.739951</td>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.733252</td>\n",
       "      <td>0.735688</td>\n",
       "      <td>0.728380</td>\n",
       "      <td>0.736297</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.409699</td>\n",
       "      <td>1.760176</td>\n",
       "      <td>2.860427</td>\n",
       "      <td>0.895036</td>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 4000, 'count...</td>\n",
       "      <td>0.739342</td>\n",
       "      <td>0.741169</td>\n",
       "      <td>0.737515</td>\n",
       "      <td>0.728989</td>\n",
       "      <td>0.729598</td>\n",
       "      <td>0.735323</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.045594</td>\n",
       "      <td>1.990009</td>\n",
       "      <td>3.630740</td>\n",
       "      <td>0.413232</td>\n",
       "      <td>3500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 3500, 'count...</td>\n",
       "      <td>0.733861</td>\n",
       "      <td>0.737515</td>\n",
       "      <td>0.719854</td>\n",
       "      <td>0.742996</td>\n",
       "      <td>0.725335</td>\n",
       "      <td>0.731912</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.492648</td>\n",
       "      <td>0.762517</td>\n",
       "      <td>1.578648</td>\n",
       "      <td>0.197762</td>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 4000, 'count...</td>\n",
       "      <td>0.735079</td>\n",
       "      <td>0.733861</td>\n",
       "      <td>0.721072</td>\n",
       "      <td>0.742996</td>\n",
       "      <td>0.726553</td>\n",
       "      <td>0.731912</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.092690</td>\n",
       "      <td>0.131392</td>\n",
       "      <td>1.514986</td>\n",
       "      <td>0.070137</td>\n",
       "      <td>5500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 5500, 'count...</td>\n",
       "      <td>0.735688</td>\n",
       "      <td>0.730816</td>\n",
       "      <td>0.725335</td>\n",
       "      <td>0.740560</td>\n",
       "      <td>0.719854</td>\n",
       "      <td>0.730451</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       18.696713      0.973825         3.762837        0.101393   \n",
       "9       15.409699      1.760176         2.860427        0.895036   \n",
       "5       17.045594      1.990009         3.630740        0.413232   \n",
       "13       7.492648      0.762517         1.578648        0.197762   \n",
       "21       7.092690      0.131392         1.514986        0.070137   \n",
       "\n",
       "   param_countvectorizer__max_features param_countvectorizer__ngram_range  \\\n",
       "1                                 3500                             (1, 1)   \n",
       "9                                 4000                             (1, 1)   \n",
       "5                                 3500                             (1, 2)   \n",
       "13                                4000                             (1, 2)   \n",
       "21                                5500                             (1, 2)   \n",
       "\n",
       "   param_logisticregression__C  \\\n",
       "1                        0.001   \n",
       "9                        0.001   \n",
       "5                        0.001   \n",
       "13                       0.001   \n",
       "21                       0.001   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "1   {'countvectorizer__max_features': 3500, 'count...           0.739951   \n",
       "9   {'countvectorizer__max_features': 4000, 'count...           0.739342   \n",
       "5   {'countvectorizer__max_features': 3500, 'count...           0.733861   \n",
       "13  {'countvectorizer__max_features': 4000, 'count...           0.735079   \n",
       "21  {'countvectorizer__max_features': 5500, 'count...           0.735688   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "1            0.744214           0.733252           0.735688   \n",
       "9            0.741169           0.737515           0.728989   \n",
       "5            0.737515           0.719854           0.742996   \n",
       "13           0.733861           0.721072           0.742996   \n",
       "21           0.730816           0.725335           0.740560   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "1            0.728380         0.736297        0.005447                1  \n",
       "9            0.729598         0.735323        0.005060                2  \n",
       "5            0.725335         0.731912        0.008327                3  \n",
       "13           0.726553         0.731912        0.007522                4  \n",
       "21           0.719854         0.730451        0.007324                5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cast to a dataframe\n",
    "pd.DataFrame(grid_lemma.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation\n",
    "\n",
    "Model Three scored very similarly to Model Two. The lemmatization of words did not improve accuracy of the model. The lemmatization of words made Model Three more computationall expensive than Model Two, it took longer to run. This trend was similar to that seen in the MultinomialNB models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Four. GridSearchCV, Stemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make logistic pipeline\n",
    "cvect_stem = CountVectorizer(stop_words = stop_word,tokenizer=StemTokenizer())\n",
    "pipe_stem = make_pipeline(cvect_stem,StandardScaler(with_mean=False),LogisticRegression(max_iter=10_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                        CountVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...],\n",
       "                                                        tokenizer=<__main__.StemTokenizer object at 0x0000026F87607760>)),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'countvectorizer__max_features': [3500, 4000, 5500],\n",
       "                         'countvectorizer__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'logisticregression__C': [0.0001, 0.001, 0.1, 1]})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate gridsearch through stemmatizer\n",
    "grid_stem = GridSearchCV(pipe_stem,param_grid=param_log,n_jobs=-1)\n",
    "\n",
    "#fit training data to gridsearch\n",
    "grid_stem.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8700365408038977"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score stemmatizer on training data\n",
    "grid_stem.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression model is 0.7293.\n",
      "The recall of the Logistic Regression model is 0.8219.\n",
      "The f1 score of the Logistic Regression model is 0.7753.\n",
      "The precision score of the Logistic Regression model is 0.7336.\n"
     ]
    }
   ],
   "source": [
    "#score on the classification metrics\n",
    "print(f'The accuracy of the Logistic Regression model is {round(grid_stem.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Logistic Regression model is {round(recall_score(y_test,grid_stem.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Logistic Regression model is {round(f1_score(y_test,grid_stem.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Logistic Regression model is {round(precision_score(y_test,grid_stem.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_countvectorizer__ngram_range</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25.912526</td>\n",
       "      <td>12.765136</td>\n",
       "      <td>6.075865</td>\n",
       "      <td>3.077493</td>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 4000, 'count...</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>0.723508</td>\n",
       "      <td>0.733252</td>\n",
       "      <td>0.745432</td>\n",
       "      <td>0.733861</td>\n",
       "      <td>0.732643</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.516339</td>\n",
       "      <td>9.557748</td>\n",
       "      <td>5.525057</td>\n",
       "      <td>2.220415</td>\n",
       "      <td>3500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 3500, 'count...</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>0.722899</td>\n",
       "      <td>0.730816</td>\n",
       "      <td>0.740560</td>\n",
       "      <td>0.730816</td>\n",
       "      <td>0.730451</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.380083</td>\n",
       "      <td>0.597279</td>\n",
       "      <td>3.692986</td>\n",
       "      <td>0.159305</td>\n",
       "      <td>3500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 3500, 'count...</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>0.724726</td>\n",
       "      <td>0.726553</td>\n",
       "      <td>0.737515</td>\n",
       "      <td>0.720463</td>\n",
       "      <td>0.727284</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.351191</td>\n",
       "      <td>10.547568</td>\n",
       "      <td>7.262039</td>\n",
       "      <td>2.305210</td>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 4000, 'count...</td>\n",
       "      <td>0.733861</td>\n",
       "      <td>0.721072</td>\n",
       "      <td>0.727771</td>\n",
       "      <td>0.738124</td>\n",
       "      <td>0.714982</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26.460594</td>\n",
       "      <td>10.074485</td>\n",
       "      <td>5.831737</td>\n",
       "      <td>2.772926</td>\n",
       "      <td>5500</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'countvectorizer__max_features': 5500, 'count...</td>\n",
       "      <td>0.735079</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>0.724726</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>0.714982</td>\n",
       "      <td>0.725213</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "13      25.912526     12.765136         6.075865        3.077493   \n",
       "5       23.516339      9.557748         5.525057        2.220415   \n",
       "1       15.380083      0.597279         3.692986        0.159305   \n",
       "9       30.351191     10.547568         7.262039        2.305210   \n",
       "17      26.460594     10.074485         5.831737        2.772926   \n",
       "\n",
       "   param_countvectorizer__max_features param_countvectorizer__ngram_range  \\\n",
       "13                                4000                             (1, 2)   \n",
       "5                                 3500                             (1, 2)   \n",
       "1                                 3500                             (1, 1)   \n",
       "9                                 4000                             (1, 1)   \n",
       "17                                5500                             (1, 1)   \n",
       "\n",
       "   param_logisticregression__C  \\\n",
       "13                       0.001   \n",
       "5                        0.001   \n",
       "1                        0.001   \n",
       "9                        0.001   \n",
       "17                       0.001   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "13  {'countvectorizer__max_features': 4000, 'count...           0.727162   \n",
       "5   {'countvectorizer__max_features': 3500, 'count...           0.727162   \n",
       "1   {'countvectorizer__max_features': 3500, 'count...           0.727162   \n",
       "9   {'countvectorizer__max_features': 4000, 'count...           0.733861   \n",
       "17  {'countvectorizer__max_features': 5500, 'count...           0.735079   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "13           0.723508           0.733252           0.745432   \n",
       "5            0.722899           0.730816           0.740560   \n",
       "1            0.724726           0.726553           0.737515   \n",
       "9            0.721072           0.727771           0.738124   \n",
       "17           0.724117           0.724726           0.727162   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "13           0.733861         0.732643        0.007469                1  \n",
       "5            0.730816         0.730451        0.005836                2  \n",
       "1            0.720463         0.727284        0.005627                3  \n",
       "9            0.714982         0.727162        0.008377                4  \n",
       "17           0.714982         0.725213        0.006438                5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cast to a dataframe\n",
    "pd.DataFrame(grid_stem.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation\n",
    "\n",
    "Model Four performed simlarly to Model Three. There are no differences, except for runtime. Model Four took a longer time to fit than Model Three. Overfitting is still present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with TfidfVectorization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model One. GridSearchCV, no Lemmatizing or Stemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipeline for basic tfidf\n",
    "tfidf = TfidfVectorizer(stop_words = stop_word)\n",
    "pipe_tfdf = make_pipeline(tfidf,StandardScaler(with_mean=False),LogisticRegression(max_iter=10_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create param grid for tfidf\n",
    "\n",
    "param_tfdf = {\n",
    "    'tfidfvectorizer__max_features': [2_400,2_500,2_600],\n",
    "    'tfidfvectorizer__ngram_range': [(1,1),(1,2)],\n",
    "    'logisticregression__C': [.0005,.0006,.0004]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...])),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': [0.0005, 0.0006, 0.0004],\n",
       "                         'tfidfvectorizer__max_features': [2400, 2500, 2600],\n",
       "                         'tfidfvectorizer__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate gridsearch for tfidf no lemmatizing or stemmatizing\n",
    "grid_tfdf = GridSearchCV(pipe_tfdf,param_grid=param_tfdf,n_jobs=-1)\n",
    "\n",
    "#fit on training data\n",
    "grid_tfdf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8515225334957369"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score on the training data\n",
    "grid_tfdf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression model is 0.7435.\n",
      "The recall of the Logistic Regression model is 0.8296.\n",
      "The f1 score of the Logistic Regression model is 0.7861.\n",
      "The precision score of the Logistic Regression model is 0.747.\n"
     ]
    }
   ],
   "source": [
    "#score on the classification metrics\n",
    "print(f'The accuracy of the Logistic Regression model is {round(grid_tfdf.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Logistic Regression model is {round(recall_score(y_test,grid_tfdf.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Logistic Regression model is {round(f1_score(y_test,grid_tfdf.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Logistic Regression model is {round(precision_score(y_test,grid_tfdf.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 0.0005,\n",
       " 'tfidfvectorizer__max_features': 2600,\n",
       " 'tfidfvectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best parameters of the gridsearch\n",
    "grid_tfdf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation\n",
    "\n",
    "Model One with TfidfVectorization also scored the same to the models with CountVectorization. TfidfVectorization measures the importance of a word based on how many times a word appears in a document versus the number of documents that word appears in. This way of numerically categorizing words did not improve the accuracy or recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Two. TfidfVectorization with Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipeline for basic tfidf\n",
    "tfidf_lemma = TfidfVectorizer(stop_words = stop_word,tokenizer = LemmaTokenizer())\n",
    "pipe_lemma = make_pipeline(tfidf_lemma,StandardScaler(with_mean=False),LogisticRegression(max_iter=10_000))\n",
    "param_tfdf_lemma = {\n",
    "    'tfidfvectorizer__max_features': [1_000,2_500,3_000],\n",
    "    'tfidfvectorizer__ngram_range': [(1,1),(1,2)],\n",
    "    'logisticregression__C': [.0005,.0001,.1,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...],\n",
       "                                                        tokenizer=<__main__.LemmaTokenizer object at 0x0000026F90151FA0>)),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': [0.0005, 0.0001, 0.1, 10],\n",
       "                         'tfidfvectorizer__max_features': [1000, 2500, 3000],\n",
       "                         'tfidfvectorizer__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate gridsearch for tfidf no lemmatizing or stemmatizing\n",
    "grid_tfdf_lemma = GridSearchCV(pipe_lemma,param_grid=param_tfdf_lemma,n_jobs=-1)\n",
    "\n",
    "#fit on training data\n",
    "grid_tfdf_lemma.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86394640682095"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score on the training data\n",
    "grid_tfdf_lemma.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression model is 0.7479.\n",
      "The recall of the Logistic Regression model is 0.8296.\n",
      "The f1 score of the Logistic Regression model is 0.789.\n",
      "The precision score of the Logistic Regression model is 0.7522.\n"
     ]
    }
   ],
   "source": [
    "#score on the classification metrics\n",
    "print(f'The accuracy of the Logistic Regression model is {round(grid_tfdf_lemma.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Logistic Regression model is {round(recall_score(y_test,grid_tfdf_lemma.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Logistic Regression model is {round(f1_score(y_test,grid_tfdf_lemma.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Logistic Regression model is {round(precision_score(y_test,grid_tfdf_lemma.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 0.0005,\n",
       " 'tfidfvectorizer__max_features': 3000,\n",
       " 'tfidfvectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tfdf_lemma.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation\n",
    "\n",
    "Adding lemmatization to the TfidfVectorization model did not significantly improve the score of the model. This model took longer to run, more computationally costly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Two. TfidfVectorization with Stemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipeline for basic tfidf\n",
    "tfidf_stem = TfidfVectorizer(stop_words = stop_word,tokenizer = StemTokenizer())\n",
    "pipe_stem = make_pipeline(tfidf_stem,StandardScaler(with_mean=False),LogisticRegression(max_iter=10_000))\n",
    "param_stem = {\n",
    "    'tfidfvectorizer__max_features': [750,1_000,1_500],\n",
    "    'tfidfvectorizer__ngram_range':[(1,1),(1,2)],\n",
    "    'logisticregression__C':[.0001,.001,.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(stop_words=['0o', '0s',\n",
       "                                                                    '3a', '3b',\n",
       "                                                                    '3d', '6b',\n",
       "                                                                    '6o', 'a',\n",
       "                                                                    'a1', 'a2',\n",
       "                                                                    'a3', 'a4',\n",
       "                                                                    'ab',\n",
       "                                                                    'able',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'abst',\n",
       "                                                                    'ac',\n",
       "                                                                    'accordance',\n",
       "                                                                    'according',\n",
       "                                                                    'accordingly',\n",
       "                                                                    'across',\n",
       "                                                                    'act',\n",
       "                                                                    'actually',\n",
       "                                                                    'ad',\n",
       "                                                                    'added',\n",
       "                                                                    'adj', 'ae',\n",
       "                                                                    'af',\n",
       "                                                                    'affected', ...],\n",
       "                                                        tokenizer=<__main__.StemTokenizer object at 0x0000026F915ABA30>)),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=10000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': [0.0001, 0.001, 0.1],\n",
       "                         'tfidfvectorizer__max_features': [750, 1000, 1500],\n",
       "                         'tfidfvectorizer__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate gridsearch for tfidf no lemmatizing or stemmatizing\n",
    "grid_tfdf_stem = GridSearchCV(pipe_stem,param_grid=param_stem,n_jobs=-1)\n",
    "\n",
    "#fit on training data\n",
    "grid_tfdf_stem.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8320341047503045"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score on the training data\n",
    "grid_tfdf_stem.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic Regression model is 0.7402.\n",
      "The recall of the Logistic Regression model is 0.8193.\n",
      "The f1 score of the Logistic Regression model is 0.7818.\n",
      "The precision score of the Logistic Regression model is 0.7477.\n"
     ]
    }
   ],
   "source": [
    "#score on the classification metrics\n",
    "print(f'The accuracy of the Logistic Regression model is {round(grid_tfdf_stem.score(X_test,y_test),4)}.')\n",
    "print(f'The recall of the Logistic Regression model is {round(recall_score(y_test,grid_tfdf_stem.predict(X_test)),4)}.')\n",
    "print(f'The f1 score of the Logistic Regression model is {round(f1_score(y_test,grid_tfdf_stem.predict(X_test)),4)}.')\n",
    "print(f'The precision score of the Logistic Regression model is {round(precision_score(y_test,grid_tfdf_stem.predict(X_test)),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 0.001,\n",
       " 'tfidfvectorizer__max_features': 1500,\n",
       " 'tfidfvectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best parameters\n",
    "grid_tfdf_stem.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation\n",
    "\n",
    "Stemmatizing the words, as seen in this model, did not improve the TfidfVectorization metrics. Stemmatizing is more computationally heavy and took a long time to run. Therefore, this model was not taken any farther."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
